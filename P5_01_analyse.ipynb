{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentez des clients d'un site e-commerce\n",
    "\n",
    "- **Projet 5 du parcours « Data Scientist » d’OpenClassrooms**\n",
    "- **Mark Creasey**\n",
    "\n",
    "## Partie 1 : Nettoyage et analyse exploratoire des données\n",
    "\n",
    "<img  width=\"76\" height=\"30\" src=\"https://olist.com/wp-custom/themes/olist20/assets/img/brand.svg\" alt=\"Logo olist\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--TABLE OF CONTENTS-->\n",
    "\n",
    "- [1. Compréhension du problème](#1.-Compréhension-du-problème)\n",
    "  - [1.1 Mission](#1.1-Mission)\n",
    "  - [1.2 Requirements : Bibliothèques utilisées dans ce notebook](#1.2-Requirements-:-Bibliothèques-utilisées-dans-ce-notebook)\n",
    "  - [1.3 Des fonctions utilitaires](#1.3-Des-fonctions-utilitaires)\n",
    "  - [1.4 Des routines statistiques](#1.4-Des-routines-statistiques)\n",
    "- [2. Import et nettoyage des données](#2.-Import-et-nettoyage-des-données)\n",
    "  - [2.1 Description des données (metadata)](<#2.1-Description-des-données-(metadata)>)\n",
    "  - [2.2 Import des données](#2.2-Import-des-données)\n",
    "  - [2.3 Description de données (après import)](<#2.3-Description-de-données-(après-import)>)\n",
    "  - [2.4 Nettoyage des données](#2.4-Nettoyage-des-données)\n",
    "- [3. Analyse Exploratoire](#3.-Analyse-Exploratoire)\n",
    "  - [3.1 Données numériques](#3.1-Données-numériques)\n",
    "  - [3.2 Données catégoriques](#3.2-Données-catégoriques)\n",
    "  - [3.3 Associations entre variables catégoriques et numériques](#3.3-Associations-entre-variables-catégoriques-et-numériques)\n",
    "- [4. Feature Engineering](#4.-Feature-Engineering)\n",
    "  - [4.1 Nouvelles 'features' catégoriques](#4.1-Nouvelles-'features'-catégoriques)\n",
    "  - [4.2 Nouvelles 'features' numériques](#4.2-Nouvelles-'features'-numériques)\n",
    "- [5. Enregistrement des données nettoyées](#5.-Enregistrement-des-données-nettoyées)\n",
    "  - [5.1 Sommaire des données nettoyées](#5.1-Sommaire-des-données-nettoyées)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Compréhension du problème\n",
    "\n",
    "## 1.1 Mission\n",
    "\n",
    "[Olist](https://olist.com/), une entreprise brésilienne qui propose une solution de vente sur les\n",
    "marketplaces en ligne, souhaite une **segmentation des clients** que ses équipes d'e-commerce pourront\n",
    "utiliser au quotidien pour leurs campagnes de communication.\n",
    "\n",
    "- **comprendre les différents types d'utilisateurs**, grâce à leur comportement et à leurs données\n",
    "  personnelles, en regroupant des clients de profils similaires. Ces catégories pourront être\n",
    "  utilisées par l’équipe Marketing pour mieux communiquer.\n",
    "\n",
    "- **fournir à l’équipe marketing une description actionable** de votre segmentation et de sa logique\n",
    "  sous-jacente pour une utilisation optimale\n",
    "\n",
    "- **une proposition de contrat de maintenance**, (fréquence à laquelle la segmentation doit être\n",
    "  mise à jour pour rester pertinente), basée sur une analyse de la stabilité des segments au cours\n",
    "  du temps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives d'analyse exploratoire\n",
    "\n",
    "- Connaitre les données\n",
    "- Nettoyer les données\n",
    "- Identifier les indicateurs actionable\n",
    "- Créer des nouvelles features / indicateurs si besoin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Requirements : Bibliothèques utilisées dans ce notebook\n",
    "\n",
    "- voir [`requirements.txt`](./requirements.txt) pour les versions des bibliothèques testées avec ce notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si ce notebook ne marche pas avec les versions\n",
    "# des bibliothèques dans votre environnement, alors\n",
    "# decommentarise la ligne suivant pour des versions testées:\n",
    "\n",
    "# %pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def install_libraries(required={}) -> None:\n",
    "    \"\"\"\n",
    "    Installation des bibliothèques manquantes\n",
    "    https://stackoverflow.com/questions/44210656/\n",
    "    \"\"\"\n",
    "    import sys\n",
    "    import subprocess\n",
    "    import pkg_resources\n",
    "    installed = {pkg.key for pkg in pkg_resources.working_set}\n",
    "    missing = set(required) - set(installed)\n",
    "    if missing:\n",
    "        print(f'missing libraries: {missing}')\n",
    "        python = sys.executable\n",
    "        subprocess.check_call([python, '-m', 'pip', 'install', *missing],\n",
    "                              stdout=subprocess.DEVNULL)\n",
    "\n",
    "\n",
    "required_libraries = {'numpy', 'pandas', 'matplotlib', 'seaborn',\n",
    "                      'scipy', 'scikit-learn', 'statsmodels',\n",
    "                      'missingno', 'dython'}\n",
    "install_libraries(required_libraries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Import des bibliothèques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import missingno as msno\n",
    "import sklearn\n",
    "import dython\n",
    "# pour calculer VIF -Variance Influence Factor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# correlations catégoriques (Cramers V, Theils U)\n",
    "from dython.nominal import associations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Liste des versions des bibliothèques utilisées\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "versions des bibliothèques utilisées:\n",
      "json==2.0.9; numpy==1.21.5; pandas==1.1.5; seaborn==0.11.2; scipy==1.7.3; missingno==0.5.0; sklearn==1.0.2; dython==0.6.8\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "python_version()\n",
    "print('versions des bibliothèques utilisées:')\n",
    "print('; '.join(f'{m.__name__}=={m.__version__}' for m in globals(\n",
    ").values() if getattr(m, '__version__', None)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Configuration défauts d'affichage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 200)  # pour afficher toutes les colonnes\n",
    "pd.set_option('display.max_rows', 10)  # pour afficher max 10 lignes\n",
    "pd.set_option('display.max_colwidth', 800)  # pour afficher toutes la text\n",
    "# pd.set_option('display.precision', 2)\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_theme(style=\"white\", context=\"notebook\")\n",
    "sns.set_color_codes(\"pastel\")\n",
    "sns.set_palette(\"tab20\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Des fonctions utilitaires\n",
    "\n",
    "### 1.3.1 Enregistrement des graphiques\n",
    "\n",
    "Pour enregistrer les graphiques, define **`SAVE_IMAGES = True`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_IMAGES = True\n",
    "IMAGE_FOLDER = './images/notebook'\n",
    "if not os.path.exists(IMAGE_FOLDER):\n",
    "    os.makedirs(IMAGE_FOLDER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_png(fig_name=None) -> None:\n",
    "    \"\"\"\n",
    "    Enregistre l'image dans un fichier,\n",
    "    il faut appeler avant plt.show() pour pouvoir ajuster la taille de l'image\n",
    "    avec bbox_inches=tight pour être sûr d'inclure le titre / legend entier.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_title():\n",
    "        if plt.gcf()._suptitle is None:  # noqa\n",
    "            return plt.gca().get_title()\n",
    "        else:\n",
    "            return plt.gcf()._suptitle.get_text()  # noqa\n",
    "\n",
    "    if SAVE_IMAGES:\n",
    "        if fig_name is None:\n",
    "            fig_name = get_title()\n",
    "        elif len(fig_name) < 9:\n",
    "            fig_name = f'{fig_name}_{get_title()}'\n",
    "        fig_name = fig_name.replace(' ', '_').replace(':', '-').replace(\n",
    "            '.', '-').replace('/', '_').replace('>', 'gt.').replace('<', 'lt.')\n",
    "        print(f'\"{fig_name}.png\"')\n",
    "        plt.gcf().savefig(\n",
    "            f'{IMAGE_FOLDER}/{fig_name}.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Vérifier que les colonnes sont dans le dataframe\n",
    "\n",
    "- sans changer l'ordre des colonnes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cols_in_df(df: pd.DataFrame, colonnes: list = None) -> list:\n",
    "    \"\"\"Procedure pour retourner les colonnes existantes dans le dataframe dans la même ordre.\n",
    "    Utiliser pour assurer que les colonnes existe.\n",
    "    \"\"\"\n",
    "    ret_cols = []\n",
    "    for col in colonnes:\n",
    "        if col in df.columns:\n",
    "            ret_cols.append(col)\n",
    "    return ret_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import et nettoyage des données\n",
    "\n",
    "Olist a fournit une [base de données](https://www.kaggle.com/olistbr/brazilian-ecommerce) anonymisée\n",
    "comportant des informations sur l’historique de commandes, les produits achetés, les commentaires de\n",
    "satisfaction, et la localisation des clients depuis janvier 2017.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Description des données (metadata)\n",
    "\n",
    "Le data schema et déscription des champs sont fournis à la même [adresse](https://www.kaggle.com/olistbr/brazilian-ecommerce) que les données:\n",
    "\n",
    "<img width=\"564\" height=\"339\" alt=\"Data Schema\" src=\"https://i.imgur.com/HRhd2Y0.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Import des données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customers.shape = (99441, 5); columns : ['customer_id', 'customer_unique_id', 'customer_zip_code_prefix', 'customer_city', 'customer_state']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_unique_id</th>\n",
       "      <th>customer_zip_code_prefix</th>\n",
       "      <th>customer_city</th>\n",
       "      <th>customer_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06b8999e2fba1a1fbc88172c00ba8bc7</td>\n",
       "      <td>861eff4711a542e4b93843c6dd7febb0</td>\n",
       "      <td>14409</td>\n",
       "      <td>franca</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18955e83d337fd6b2def6b18a428ac77</td>\n",
       "      <td>290c77bc529b7ac935b93aa66c333dc3</td>\n",
       "      <td>9790</td>\n",
       "      <td>sao bernardo do campo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e7b3e00288586ebd08712fdd0374a03</td>\n",
       "      <td>060e732b5b29e8181a18229c7b0b2b5e</td>\n",
       "      <td>1151</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b2b6027bc5c5109e529d4dc6358b12c3</td>\n",
       "      <td>259dac757896d24d7702b9acbbff3f3c</td>\n",
       "      <td>8775</td>\n",
       "      <td>mogi das cruzes</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4f2d8ab171c80ec8364f7c12e35b23ad</td>\n",
       "      <td>345ecd01c38d18a9036ed96c73b8d066</td>\n",
       "      <td>13056</td>\n",
       "      <td>campinas</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        customer_id                customer_unique_id  \\\n",
       "0  06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0   \n",
       "1  18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3   \n",
       "2  4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e   \n",
       "3  b2b6027bc5c5109e529d4dc6358b12c3  259dac757896d24d7702b9acbbff3f3c   \n",
       "4  4f2d8ab171c80ec8364f7c12e35b23ad  345ecd01c38d18a9036ed96c73b8d066   \n",
       "\n",
       "   customer_zip_code_prefix          customer_city customer_state  \n",
       "0                     14409                 franca             SP  \n",
       "1                      9790  sao bernardo do campo             SP  \n",
       "2                      1151              sao paulo             SP  \n",
       "3                      8775        mogi das cruzes             SP  \n",
       "4                     13056               campinas             SP  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = 'data/raw'\n",
    "\n",
    "\n",
    "def load_dataset(set_name='customers'):\n",
    "    filename = f'{DATA_DIR}/olist_{set_name}_dataset.csv'\n",
    "    df = pd.read_csv(filename)\n",
    "    print(f'{set_name}.shape = {df.shape}; columns : {list(df.columns)}')\n",
    "    return df\n",
    "\n",
    "\n",
    "customers = load_dataset('customers')\n",
    "\n",
    "customers.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargé les autres datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geolocation.shape = (1000163, 5); columns : ['geolocation_zip_code_prefix', 'geolocation_lat', 'geolocation_lng', 'geolocation_city', 'geolocation_state']\n",
      "order_items.shape = (112650, 7); columns : ['order_id', 'order_item_id', 'product_id', 'seller_id', 'shipping_limit_date', 'price', 'freight_value']\n",
      "order_payments.shape = (103886, 5); columns : ['order_id', 'payment_sequential', 'payment_type', 'payment_installments', 'payment_value']\n",
      "order_reviews.shape = (99224, 7); columns : ['review_id', 'order_id', 'review_score', 'review_comment_title', 'review_comment_message', 'review_creation_date', 'review_answer_timestamp']\n",
      "orders.shape = (99441, 8); columns : ['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
      "products.shape = (32951, 9); columns : ['product_id', 'product_category_name', 'product_name_lenght', 'product_description_lenght', 'product_photos_qty', 'product_weight_g', 'product_length_cm', 'product_height_cm', 'product_width_cm']\n",
      "sellers.shape = (3095, 4); columns : ['seller_id', 'seller_zip_code_prefix', 'seller_city', 'seller_state']\n"
     ]
    }
   ],
   "source": [
    "geolocation = load_dataset('geolocation')\n",
    "order_items = load_dataset('order_items')\n",
    "order_payments = load_dataset('order_payments')\n",
    "order_reviews = load_dataset('order_reviews')\n",
    "orders = load_dataset('orders')\n",
    "products = load_dataset('products')\n",
    "sellers = load_dataset('sellers')\n",
    "product_category_names = pd.read_csv(\n",
    "    'data/raw/product_category_name_translation.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Description de données (après import)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Nettoyage des données\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Analyse Exploratoire\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Données numériques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Données catégoriques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Associations entre variables catégoriques et numériques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Nouvelles 'features' catégoriques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Nouvelles 'features' numériques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Pipeline de Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Enregistrement des données nettoyées\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Sommaire des données nettoyées\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "08f54268de9884c973a82c2c5267bbf1de8fae7577a142dd199c5c3f90c0dd65"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 ('OC_3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
